%
% File acl2014.tex
%
%% Template Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith
%% 
%% Template Customized by Norbert Eke

\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage[table,xcdraw]{xcolor}
\usepackage{times}
\usepackage{url}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{textcomp}

\newcommand{\R}{\mathbb{R}}
\graphicspath{{images/}}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Identification and Classification of Sexual Predatory Behavior in Online Chat-Room Environments}

\author{Norbert Eke \\
  UBC Okanagan \\
  Kelowna, BC, Canada \\
 \And
  Abdallah Mohamed \\
  UBC Okanagan \\
  Kelowna, BC, Canada \\
  {\tt norberteke@protonmail.com \tab  $\left\{\tt abdallah.mohamed, jeff.andrews \right\}$\tt @ubc.ca} \\
  \And
  Jeffrey Andrews \\
  UBC Okanagan \\
  Kelowna, BC, Canada \\
 }

\date{}

\begin{document}
\maketitle

\begin{abstract} According to the \textit{Crimes Against Children Research Center}, one in five U.S. teenagers who regularly use the Internet have received an unwanted sexual solicitation via the web. There is an increasing danger in online environments such as chat-rooms, where predatory behaviour is more and more frequent, creating an unsafe environment for minors. 
This project aims to design an approach for online communities to enhance their member's safety by detecting malicious conversations of sexual nature. This project joins the powers of computational linguistics with statistical machine learning to decipher the insight lying in conversations, then make predictions on whether or not a specific conversation should be flagged for containing sexual predatory behaviour. 
The contribution of this novel approach is 2-fold: firstly, the approach is able to capture the contextual details by putting an emphasis on insight that lies within the conversation, and secondly it contains a 2 stage classification system, which is highly flexible and customizable for detecting and classifying other malicious textual data. 
\end{abstract}

\section{Introduction}
Members of online communities face more danger than ever before, with a significant increase in the number of aggressive sexual predators present online \cite{wolak2008online}. Some statistics say ``most first encounters between offenders and victims (76\%) happened in online chat rooms" \cite{wolak2004internet}. According to Wolak et al. (2008), online sexual predators ``do not appear to be stalking unsuspecting victims, but rather continuing to seek youth who are susceptible to seduction". Now more than ever there is a need for better intelligent systems that are capable of accurately detecting sexual predator's dangerous behavior online.

\subsection{Previous Work}
A variety of research has been done on malicious and dangerous behavior detection and classification based on textual analysis. The detection of online bullying has been previously addressed by numerous researchers like \cite{nandhini2015online}, and \cite{nalini2015classification}, who considered analyzing textual data from social networking websites. Other types of dangerous behavior detection include crime pattern detection \cite{nath2006crime}, harmful language detection \cite{munezero2013antisocial}, deception detection \cite{fuller2011investigation}, depression detection \cite{wang2013depression}, and sexual predator detection \cite{inches2012overview}. The majority of these approaches apply feature extraction and text mining techniques, alongside topic modeling or learning algorithms, before finishing it off with text classifiers predicting for new textual data.

Sexual predator identification became a popular research topic in 2012, when Inches and Crestani created labeled data-sets for a sexual predator identification competition\footnote{http://pan.webis.de/clef12/pan12-web/author-identification.html}. The two main tasks of the competition included the identification of predators within all users and identification of parts of predator conversations which are the most distinctive of the predator bad behavior. Several approaches have been submitted to this competition in the past. \cite{morris2012identifying} used SVM classification\footnote{\cite{cortes1995support}} with a bag-of-words model, alongside a manually constructed ``blacklist" of words. \cite{vilarinoinformation} used a Multinomial Naive Bayes\footnote{Multinomial Naive Bayes classifier: \cite{mccallum1998comparison}} model for predator classification alongside an information retrieval based approach. \cite{brooke2012paragraph} looked at clustering paragraphs using Latent Semantic Indexing\footnote{Latent Semantic Indexing: \cite{deerwester1990indexing}} to find paragraphs containing sexual predatory behaviour, while \cite{bogdanova2012impact} used language based feature extraction techniques with a Naive Bayes classifier to detect predators. Villatoro-Tello et al. applied a two step approach to detect misbehaving users by focusing on ``suspicious conversations identification" and ``victim from predator disclosure" \cite{villatoro2012two}. Finally, \cite{kang2012ir} applied k-NN classification\footnote{ k-NN classification: \cite{ripley2007pattern}} alongside an information retrieval based approach to detect ``abnormal chat users".

The common element in almost all approaches is a machine learning model acting as a text classifier. There has been extensive research done on which learning algorithms could be best applied to text classification. \cite{lilleberg2015support} showed that SVM classifiers applied with weighted Word2Vec\footnote{Word2Vec model: \cite{mikolov2013efficient}} models work well for text classification tasks. In \cite{bijalwan2014knn}'s work one could observe how k-NN classifier outperformed Naive Bayes and Term-Graph models for the task of text classification. However, \cite{selvi2017text}'s work suggest that the Rocchio and Random Forest Algorithms\footnote{Random Forest: \cite{breiman2001random}} work better than fuzzy relevance clustering, Multi-label k-NN or Naive-Bayes Algorithms for text categorization. Finally, \cite{shafiabady2016using} proposed a new way of performing text classification by applying an unsupervised clustering approach to train SVM classifiers, which resulted in reducing the high dimensional nature of the textual data.

%%\cite{sebastiani2002machine}
\subsection{Contribution and Significance}
The contribution of this project is 2-fold. Firstly, a new approach is proposed to sexual predator identification by putting an emphasis on the insight that lies within the contextual details of a conversation. Research is focused on analyzing the entire conversation and deciding if it contains sexual predatory behaviour, as opposed to previous approaches, which focused on either identifying the predators among all users in the different conversations or identifying the parts of the conversations which are the most distinctive of the predator behaviour. What makes this approach unique is the emphasis on contextual details. Secondly, a new two stage classification system is introduced to detect potential predatory behaviour and classify them into 3 groups of potential levels of maliciousness. The experimental process of coming up with the classification system yielded performance results from 8 different classification models, which is also part of the contribution.

The significance of this project is 3-fold. Firstly, this approach significantly helps online communities to enhance their member's safety by detecting malicious conversations of sexual nature. Secondly, the algorithm designed in this project is significant, since it furthers research conducted in the area of sexual predator detection. Thirdly, the two stage classification system is a highly flexible method, therefore future research can be focused on customizing this approach to other types of dangerous behavior detection mentioned in the previous section.

\section{Research Questions and Objectives}
\indent The main goal of this research project is to design an approach that can detect and classify textual data as containing sexual predatory or non-predatory behaviour. Applying such an approach to online chat-room conversations would have to take into consideration the messy and difficult to interpret nature of the text. Textual data coming from online environments could be expected to be full of misspelled words, slang, internet acronyms, inappropriate language and broken grammar being used. One of the major tasks in this project is reconstruction of the linguistic context of words and phrases being used in a conversation. Modern computational linguistics use complex deep learning language models to capture the semantic similarity between words and concepts, thus mapping the ``meaning of words and concepts" to high dimensional word vector spaces. 

\indent This research project aims to join the powers of computational linguistics with statistical machine learning to decipher the insight lying in conversations, then make predictions on whether or not a specific conversation should be flagged for containing sexual predatory behaviour. Such a powerful approach could be applied in online gaming chat-room environments, where children could be disposed to being manipulated or preyed on by sexual predators. This project's sole purpose is to design an approach that could help online communities keep their members safer using an automated chat-room filter, which goes through conversations and classifies them into groups based on the uncertainty of detected malicious content.

\indent This research project initially aimed to answer the following research questions:

Q1: How to make modern computational language techniques and models adapt to the difficult to interpret nature of online conversations?

Q2: How to extract semantic details' from conversations, such that conversations containing malicious intent could be detected?

Q3: What kind of classification system and what statistical machine learning models can make a difference and predict whether or not a conversation contains sexual predatory behavior?

\section{Algorithm Proposed}
The input of this algorithm is parsed as a CSV file containing all conversation data. This file should have individual columns for conversation-id, conversation line number, author/ author-id for the line, text content in that line, and a conversation label (being a binary value of 0 or 1, 0 meaning the conversation contains no predatory behavior, 1 meaning predatory behavior).

\subsection{Data Manipulation and Text Pre-processing}
Given a CSV file containing all conversation data, one needs to parse each conversation to combine all lines within a conversation into one textual observation, then pre-process the text, and attach the appropriate labels to each conversation. For text pre-processing a number of text cleaning techniques have been considered, like removal of extra white spaces and HTML tags or links, also removal of numerical characters. All characters have been converted to lowercase and the autocorrect\footnote{https://github.com/phatpiglet/autocorrect} \cite{mccallum_2016} library's spelling corrector was also used. Conversations containing less than 3 words would be removed. The pre-processed text output is a text file, with each line containing a conversation label and the entire conversation.

%% The goal was to parse each conversation in such a way to combine all lines in each conversation into one textual observation, then pre-process the text for each conversation, and attach the labels to it.

\subsection{Vector Representation of Words}
In order to create quantitative attributes about the content of conversations, the use of vector representation of words was needed. One of the most famous deep learning models that allows the computation of vector representations of words is Google's Word2Vec.

Word2Vec is a deep learning model takes a textual data as input and produces high dimensional vector representations of words as output. In a Google blog post the algorithm is described as ``it constructs a vocabulary from the training text data and then learns vector representation of words. The resulting word vector file can be used as features in many natural language processing and machine learning applications" \cite{mikolov_2013}. 
These word vectors are also called word embeddings, and they are the output of the Word2Vec model. The model is trained to reconstruct the linguistic context of words by placing the vectors of words used in the same context close to each other. Word embeddings are also useful, since they are ``good at capturing syntactic and semantic regularities in language`` \cite{mikolov2013linguistic}, by placing the vectors of similar words closer to each other. Figure \ref{fig:word2vec} offers a visual explanation of how Word2Vec works and how it is used.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.32]{images/word2vec.png}
    \caption{Detailed Overview of the Deep Learning Model Called Word2Vec. Image credits go to \cite{Kevin2015}.}
    \label{fig:word2vec}
\end{figure}

More details about the model architecture of Word2Vec can be found in Mikolov et al's paper \cite{mikolov2013efficient}.

If dimensionality reduction would be performed on word embeddings, these semantic regularities be visualized in so called low dimension word vector spaces. A good example of such vector space can be seen in Figure \ref{fig:vectorSpace}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.65]{images/vectorSpace.JPG}
    \caption{Photo Credit to \cite{Vidhya}. Three dimensional vector space, which contains the vectors `Man', `Woman', `King', `Queen'. `Man' and `Woman' are related to each other the same way as `King' and `Queen' are related to each other, since the vectors in between them describe the male-female relationship.}
    \label{fig:vectorSpace}
\end{figure}

In terms of the algorithm proposed, these word embeddings were created by taking all pre-processed words used in all available conversations and train a large Word2Vec model, which converts each unique word into a high dimensional vector. Each unique word became part of a training text corpus that was used as input for the Word2Vec model. In order to train the Word2Vec model, Gensim\footnote{https://radimrehurek.com/gensim/} \cite{rehurek_lrec} python library's implementation of Word2Vec was used. Gensim's implementation requires the text corpus and size of word vectors as parameters. $size = 400$, $workers=20$ and a text file containing a pre-processed conversation for each line were the parameters given for the trained model. $size = 400$ was chosen on an experimental basis, as 100, 200, 300, 400 and 500 were considered, but word vectors of size 400 appeared to work best with the classifications models discussed later. The Word2Vec model created a vector representation of each unique word used somewhere within a conversation, thus a conversation can be represented as set of $n$ word vectors, where $n$ is the number of words present in that specific conversation. 

\subsection{Feature Extraction using Word Embedding Aggregation}
The most important aspect of this algorithm is putting the emphasis on contextual details within the conversation. More specifically, the emphasis is on the insight found in the contextual details of a conversation. Having a 400 dimensional word vector represent each word and $n$ word vectors represent a conversation provides the opportunity to dig deep into the contextual details of conversations and potentially find some insight about the content of the conversation. 

Using the word vectors coming from the Word2Vec model is a good starting point for learning the context of a conversation, but a better approach includes an extra step, which is feature extraction. Traditionally, feature extraction is done with the help of dimensional reduction algorithms such as Principle Component Analysis, or variable selection methods such as LASSO. Word embeddings are used to extract contextual details from textual data, therefore a word vector specific technique called ``word embedding aggregation" \cite{de2016representation} was used to extract features. De Boom et al. noted that aggregating word embeddings through a mean, max, min function is one of the easiest and most widely used techniques to derive sentence embeddings. 

In the data manipulation section it was mentioned that each conversation is being concatenated into one very long sentence, which seemed like an odd choice for data manipulation. The real purpose of conversation concatenation is to set up conversations to be aggregated into ``conversation embeddings", using Word2Vec embeddings and De Boom et al.'s word embedding aggregated sentence embeddings. 
Based on De Boom et al.'s results, the algorithm makes use of coordinate-wise min and max functions applied to each word embedding within a conversation. This approach works well, assuming that ``conversation embeddings" behave the same way as sentence embeddings. If the vectors for the $n$ words in the conversation are $v_1$, $v_2$, \dots, $v_n \in \R_{d}$, then the computation of min($v_1$,$v_2$,\dots,$v_n$) and max($v_1$,$v_2$,\dots,$v_n$) are needed. What this means is that the coordinate-wise minimum vector and maximum vector of $n$ word vectors within a conversation become 2 separate feature vectors. 

Finally, as suggested in De Boom et al.'s work, the concatenation of these two feature vectors results in obtaining a coordinate-wise min-max feature vector for feature extraction purposes. In this project, the word embeddings are 400 dimensional, so the concatenation of coordinate-wise minimum and maximum vectors results in an 800 dimensional feature vector.

\subsection{Two Stage Classification System}
After performing feature extraction using word embedding aggregation, the 800 dimensional feature vectors can be fed into various classification models. These machine learning classification models will separate conversations that contain predatory behaviour from the ones that do not contain. Various binary classification models were considered: Linear Discriminant Analysis \cite{ripley2007pattern}, Support Vector Machine Classifier \cite{fan2008liblinear}, LASSO and Ridge Classifier \cite{friedman2010regularization}, Random Forest Classifier \cite{breiman2001random}, Bagging Classifier \cite{breiman1996bagging}, Generalized Boosted Classifier \cite{ridgeway2006gbm}, AdaBoost Classifier \cite{freund1996experiments} and \cite{hastie2009multi}, kNN Classifier \cite{ripley2007pattern} and Multinomial Naive Bayes Classifier \cite{mccallum1998comparison}. 

After fitting numerous classification models, the results indicated that no model is able to minimize false positives and false negatives in the same time. Some models are better at minimizing one over the other, but no models can do it both, and still be predict accurately. Therefore, based on these observations a solution was to design two stage classification system, where two different classifiers would be trained.

\subsubsection{First Stage Classifier}
The first classifier reduces the number of false negatives (predatory conversations labelled as non-predatory), minimizing Type II errors.
This first stage classifier is trained to predicts a conversation as containing or not containing predatory behaviour. Using the first stage classifier, the predicted groups can be interpreted the following ways: 
\begin{enumerate}
    \item Conversations predicted by the first stage classifier as containing non-predatory behaviour: these are conversations that most likely do not contain predatory behaviour.
    \item Conversations predicted by the first stage classifier as containing predatory behaviour: these are conversations that need to be looked at again, by a secondary classifier for filtering out false positives.
\end{enumerate}

A comparison of different first stage classification models' performance can be found in the Results section, but it is worth noting that the Linear Discriminant Analysis Classifier was chosen as the first stage classifier, purely based on cross validated error rate and precision measurements.

\subsubsection{Second Stage Classifier}
The second stage classifier filters through all conversations labelled by the first stage classifier as containing possible predatory behaviour, reducing the number of false positives (non-predatory conversations labelled as predatory), minimizing Type I errors. Using the second stage classifier, the predicted groups can be interpreted the following ways: 
\begin{enumerate}
    \item Conversations predicted by the second stage classifier as containing non-predatory behaviour: these are conversations that possibly could contain predatory behaviour
    \item Conversations predicted by the second stage classifier as containing predatory behaviour: these are conversations that most likely contain predatory behaviour
\end{enumerate}

A comparison of different second stage classifier's performance can be found in the Results section, but it is worth noting that the AdaBoost Classifier \cite{freund1996experiments} was chosen as the second stage classifier, purely based on cross validated error rate, precision and recall measurements.

Overall, the 2 stage classification system generates 3 groups, in increasing danger levels: conversations most likely not containing predatory behaviour,  conversations possibly containing predatory behaviour and conversations most likely containing predatory behaviour. This resulted from 2 groups found by the first stage classifier, then the second stage classifier breaks down one of the first classifier's groups into 2 separate groups. This results in a hierarchical relationship between the groups.

\subsection{Algorithm Overview}
\begin{enumerate}
    \item Parse each conversation to combine all lines in each conversation into one textual observation, pre-process the text for each conversation, and attach the labels to it 
    \item Take all pre-processed words used in the whole dataset of conversations and train a 400 dimensional Word2Vec model, which converts each unique word into a 400 dimensional vector.
    \item For each conversation aggregate a min and a max feature vector by taking the min/max of each dimension from all words present in a specific conversation. This will result in a 400 dimensional min feature vector and a 400 dimensional max feature vector for each conversation.
    \item To obtain an 800 dimensional conversation feature vector, for each conversation concatenate the min and max feature vectors.
    \item Perform Linear Discriminant Analysis on the whole dataset of conversation feature vectors, to classify conversations as predatory vs. no-predatory behaviour (First stage classifier).
    \item Take all conversations that have been labelled to contain predatory behaviour and feed them into an AdaBoost model to filter out conversations that contain non-predatory behaviour, but have been labeled as containing predatory behaviour (Second stage classifier).
    \item Obtain 3 different groups of conversation, differentiated by their danger levels:
    \begin{itemize}
        \item Group A = conversations most likely do not contain predatory behaviour: Linear Discriminant Analysis model predicted the conversation to contain non-predatory behaviour 
        \item Group B = conversations possibly could contain predatory behaviour: AdaBoost model predicted the conversation to contain non-predatory behaviour, but Linear Discriminant model predicted it to contain predatory behavior
        \item Group C = conversations most likely contain predatory behaviour: AdaBoost model predicted the conversation to contain predatory behaviour
    \end{itemize}
\end{enumerate}

\section{Case Study Results and Discussion}
\subsection{Sexual Predatory Conversation Identification Task}
A controlled case study was conducted on a Sexual Predatory Conversation Identification task, similar to the Sexual Predator Identification tasks \cite{inches2012overview}. The data-set used for this controlled case study is the test set coming from Inches and Crestani's work. The test set was chosen over the training set, since the two set's ground truth labels are different, and only the test set's labels matched the controlled case study's needs.

This controlled case study differs from Inches and Crestani's Sexual Predator Identification tasks. Its aim is to focus on analyzing a whole conversation and deciding if it contains predatory behaviour, instead of identifying the predators among all users in different conversations or identifying the part of the conversations which are the most distinctive of predatory behaviour. 

Inches and Crestani's test set provides an xml file, containing 155128 conversations, alongside author and line meta-data. A ground-truth label file is also given, containing conversations id's and lines id's of those lines considered suspicious (of a perverted behavior) in a particular conversation. Given this data, the conversation xml file was processed into a csv file, with columns containing conversation id, line number, author, text and each row representing a line within a conversation. To get the data in the format described at the beginning of section 3, the conversion of predatory line labels to conversation level labels was needed. In order to do so, each conversation's line level labels were checked, and a new label of 0 (non-predatory) or 1 (predatory) was assigned if any of the conversation's lines contained predatory behaviour.

%% TO DO: Explain (better): Sample size being too large, taking a smaller random sample

After these initial data processing steps, the whole algorithm described in section 3 was executed. The sample size of the conversations data-set is 155128 observations, which is a large sample size. In order to speed up the computational process, a sample of 100000 conversations was taken. In this random sample 99450 conversations had the label 0, meaning no predatory behaviour has been identified within the conversation, and 550 conversations had the label 1, suggesting that predatory behaviour is present within the conversation. A seed number of 2017 was used in order to create reproducible results. The final results of this controlled case study were the classification results obtained from the 2 stage classification system. K-fold cross validation was used to assess the performance of various classification models on the feature vectors extracted from each conversation. $k=10$ was chosen for the number of folds in the cross validation process.

\subsection{First Stage Classification Results}
In section 3.4 a list of potential classification models were provided. In the first stage classification process LASSO, Linear Discriminant Analysis, Support Vector Machine, Random Forest, Bagging, Generalized boosted models have been tested out. The Random Forest model consistently outperformed the Bagging model, and since both of them as similar, the Bagging model was dropped.

The two groups within the data-set are massively unbalanced, thus measuring the error rate of classifiers would be a mistake. Instead, recall and precision measurement for the predatory behavior labels, and F-scores are taken into consideration \cite{sokolova2009systematic}. F-scores, recall and precision for predatory labels is calculated as per Table 2 in Sokolova and Lapalme's work. In statistical analysis of binary classification the F-score is a harmonic mean of precision and recall and it has a parameter, $\beta$. This parameter is just a constant, that places more emphasis on either the precision or recall. For the purposes of this binary classification tasks a $\beta$ of value 1 was chosen, which makes the F-scores F1-scores, and it equally weights recall and precision, while punishing extreme recall or precision values. Table 1 contains the average precision and recall measurements from each fold within the the cross validation process, also the overall F1-score for each model. All results are color coded based on cross-comparisons done between each model's average recall, precision and F1 scores. All values are percentage rates, and lower values within the table are red, while higher values are represented with the green color cells within the table.

\begin{table}[]
\centering
\label{firstStageTable}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Classification\\ Model\end{tabular}}  & \textbf{\begin{tabular}[c]{@{}c@{}}Average\\ Recall\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Average\\ Precision\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}F1\\ Score\end{tabular}} \\ \hline
\textbf{LDA}                                                         & \cellcolor[HTML]{FE0000}\textbf{0.5223}                           & \cellcolor[HTML]{2CED14}\textbf{0.9144}                              & \cellcolor[HTML]{2CED14}\textbf{0.6648}                     \\ \hline
\textbf{SVM}                                                         & \cellcolor[HTML]{2CED14}\textbf{0.7664}                           & \cellcolor[HTML]{2CED14}\textbf{0.6585}                                   & \cellcolor[HTML]{2CED14}\textbf{0.7084}                     \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Random\\ Forest\end{tabular}}     & \cellcolor[HTML]{2CED14}\textbf{0.8241}                           & \cellcolor[HTML]{FE0000}\textbf{0.2982}                              & \cellcolor[HTML]{FE0000}\textbf{0.4379}                     \\ \hline
\textbf{LASSO}                                                       & \cellcolor[HTML]{2CED14}\textbf{0.6739}                                  & \cellcolor[HTML]{2CED14}\textbf{0.6492}                                   & \cellcolor[HTML]{2CED14}\textbf{0.6613}                     \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Gr. Boosting \\ Machine\end{tabular}} & \cellcolor[HTML]{2CED14}\textbf{0.8646}                                  & \cellcolor[HTML]{FE0000}\textbf{0.3018}                                   & \cellcolor[HTML]{FE0000}\textbf{0.4474}                               \\ \hline
\end{tabular}
\caption{Average Recall and Precision, and Overall F1-Score from the top 5 First Stage Classification Models.}
\end{table}

As previously established, the first stage classifier needs to reduce the number of false negatives (predatory conversations labelled as non-predatory), therefore the model with the highest average precision value is the best first stage classifier. Random Forest has a large recall average value of 0.8241, but its average precision is only 0.2982, thus it is not an appropriate first stage classifier. Its F1-score is under 0.5 which makes it an ineffective classifier for the overall classification task. Nonetheless, the Random Forest model is good at detecting non-predatory conversations labelled as predatory. The Support Vector Machine (SVM) classifier has a lower average precision value (0.6585) than its average recall value (0.7664), therefore it does not minimize the number of false negatives, and it can not be used as a first stage classifier. Its F1-score is 0.7084, which is acceptable, but using this SVM classifier will result in balancing out recall with precision, without focusing on minimizing either, therefore this model is not perfect for providing the best results. The LASSO model's performance is very similar to SVM's case, having an F1-score of 0.6613. LASSO has almost equal precision (0.6492) and recall (0.6739) values, having the same problem as the SVM model, not minimizing the number of false negatives, thus not being a good first stage classifier. Also worth noting that the Gradient Boosting Machine model's performance is really similar to the performance of the Random Forest model. Both models are good at detecting non-predatory conversations labelled as predatory, average recall being 0.8646, but they both have really poor average precision performance (0.3018), thus they are ineffective at detecting predatory conversations accurately. Finally, Linear Discriminant Analysis (LDA) minimizes the number of false negatives, having the largest average precision value at 0.9144, therefore it was chosen as the First Stage Classifier. The LDA classifier is very good at identifying conversations that contain predatory behavior, but its very low recall rate of 0.5223 shows that this model can not solve all the problems at once. The low recall rate created a concern over the large number of false positives, which triggered the addition of a second stage classifier. The second stage classifier should be focused on filtering out false positives, while not creating a large number of false negatives. Figure 3 below shows the confusion matrix, after predicting for the left-out subset of observations during the cross validation process for the LDA model.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.50]{images/ldaCV.png}
    \caption{Confusion Matrix from the Cross Validated LDA model results.}
    \label{fig:ldaCV}
\end{figure}

As shown in Figure \ref{fig:ldaCV}, the LDA model correctly classifies 503 out of 550 predatory conversation, out of a total of 100000 conversations. This model minimizes the number of undetected predatory conversations, which makes this model so effective, with a large average precision value. However if one looks at the F1-score, it is noticeably low, only 0.6648, which is understandable, since the average recall is only 0.5223. It can be concluded that the LDA model in only good at precision, and it is ineffective at detecting non-predatory conversations labelled as predatory, where it mis-classifies conversations about half of the times. Models like Random Forest and SVM are good at this this specific task, so a second stage classifier in addition to the LDA model would help. 

\subsection{Second Stage Classification Results}
For the Second Stage Classification process the following classifiers have been trained: LASSO, Ridge Classifier, Naive Bayes Classifier, k-NN Classifier, Linear Discriminant Analysis, Support Vector Machine Classifier, Random Forest Classifier, Bagging Classifier and AdaBoost Classifier.

The second stage classifier's emphasis is on filtering through all conversations labelled by the first stage classifier (LDA) as containing predatory behaviour, reducing the number of false positives (non-predatory conversations labelled as predatory), thus minimizing Type I error. Since the second stage classifier only filters through flagged conversations, there is no need to classify all 100000 conversations, only those labelled by the LDA model as predatory (961 conversations, from Figure \ref{fig:ldaCV}).

Table 2 contains the 5 best models built for the second stage classification process. The performance results from these 5 models are cross validated and average precision and recall measurements from each fold within the cross validation process are returned, alongside the overall F1-score for each model. All results are color coded based on cross-comparisons done between each model's average recall, precision and F1 scores.

\begin{table}[]
\centering
\label{secondStageTable}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Classification\\ Model\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Average\\ Recall\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Average\\ Precision\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}F1\\ Score\end{tabular}} \\ \hline
\textbf{SVM}                                                            & \cellcolor[HTML]{FE0000}\textbf{0.6934}                           & \cellcolor[HTML]{2CED14}\textbf{0.8246}                              & \cellcolor[HTML]{2CED14}\textbf{0.7533}                     \\ \hline
\textbf{Naive Bayes}                                                    & \cellcolor[HTML]{FE0000}\textbf{0.5858}                           & \cellcolor[HTML]{2CED14}\textbf{0.9285}                              & \cellcolor[HTML]{2CED14}\textbf{0.7184}                     \\ \hline
\textbf{LASSO}                                                          & \cellcolor[HTML]{2CED14}\textbf{0.7442}                           & \cellcolor[HTML]{2CED14}\textbf{0.7711}                              & \cellcolor[HTML]{2CED14}\textbf{0.7574}                     \\ \hline
\textbf{AdaBoost}                                                       & \cellcolor[HTML]{2CED14}\textbf{0.7767}                           & \cellcolor[HTML]{2CED14}\textbf{0.8091}                              & \cellcolor[HTML]{2CED14}\textbf{0.7926}                     \\ \hline
\textbf{k-NN}                                                           & \cellcolor[HTML]{FE0000}\textbf{0.6279}                           & \cellcolor[HTML]{2CED14}\textbf{0.8966}                              & \cellcolor[HTML]{2CED14}\textbf{0.7385}                     \\ \hline
\end{tabular}
\caption{Second stage classification process, with cross validated results from the top 5 models, and their average precision, recall measurements, alongside F1-scores.}
\end{table}

The five best classifiers for the second stage classification process were SVM, Naive Bayes, LASSO, k-NN, and AdaBoost. Looking at the F1-scores, all 5 models have F1-values between 0.7 and 0.8, therefore all 5 models are competitive at filtering out the mistakes that the LDA model does in the first stage classification. The Naive Bayes and k-NN classifier's performance is quite similar, by having similarly large average precision values, 0.9285 for Naive Bayes, and 0.8966 for the k-NN model, but they both lack performance in average recall, where the values are quite low, 0.5858 and 0.6279 respectively. Overall, both have over 0.7 F1-scores, but the conclusion is that both Naive Bayes and k-NN models are effective at precision, but not at recall, and that leaves quite room for plenty of mis-classifications. A good second stage classifier would need to be really effective at both precision and recall, since if the chosen classifier would be optimized to minimize just one of precision or recall, a third stage classifier would be needed. Through observing the SVM model, it has a 0.7533 F1-score, which is larger than the previous 2 models, and even the average precision is over 0.8. but the average recall value is just shy of 0.7. Unfortunately the SVM model's performance has more emphasis on precision, therefore choosing such a model as the second stage classifier would result in having the same problem as with the Naive Bayes and k-NN classifier models. Looking at the LASSO model's performance, it has an F1-score of 0.7574, which is better than all previous second stage classifier models. Its average recall is 0.7442, and precision is 0.7711, which makes it an effective and recall and precision-wise balanced model. This LASSO model would be a good choice for the second stage classifier, but there is one problem: the AdaBoost model outperforms the LASSO model. AdaBoost has an average recall of 0.7767 and average precision of 0.8091, making its F1-score 0.7926, just shy of 0.80. This model performed the best at filtering out mis-classifications that the first stage classifier made, and it achieves equally large and balanced performance on both recall and precision, making the second stage classifier a complete system for accurate classification, without needing a third classifier. Figure 4 below shows the confusion matrix, after predicting for the left-out subset of observations during the cross validation process for the AdaBoost second stage classifier model.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{images/adaboost_cv2.png}
    \caption{AdaBoost Second stage Classification Result's Confusion Matrix}
    \label{fig:adaBoostCV}
\end{figure}

As shown in Figure \ref{fig:adaBoostCV}, the AdaBoost model correctly classifies 407 out of 503 predatory conversation. It also only mis-classifies 117 out of 458 non-predatory conversations. This AdaBoost model is as effective as it can be at minimizing errors made on both Type I and Type II errors, having large values for both average precision and recall. It can be concluded that the AdaBoost model is effective at filtering out mis-classifications made by the LDA first stage classifier. The combination of LDA as first stage classifier and AdaBoost as the second stage classifier answers one of the research questions asking ``what kind of classification system and what statistical machine learning models can make a difference and predict whether or not a conversation contains sexual predatory behavior?".

\subsection{System-wide Classification Results}
In order to re-assure that LDA and AdaBoost are the best 2 models for the two stage classification system, Table 3 shows the Recall, Precision and F1-scores for LDA, the first stage classifier, combined with each possible second stage classifier. These values are obtained by fitting, then predicting using the first stage classifier, then using the second stage classifier to filter all observations that the first stage classifier flagged as potential predatory conversations.

\begin{table}[]
\centering
\label{TwoStageClassificationResults}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}System of\\ Classifiers\end{tabular}} & \textbf{Recall}                                                & \textbf{Precision}                      & 
\textbf{\begin{tabular}[c]{@{}c@{}}F1\\ Score\end{tabular}}             \\ \hline
\textbf{LDA $\,\to\,$ SVM}                                                       & \cellcolor[HTML]{FE0000}{\color[HTML]{333333} \textbf{0.6928}} & \cellcolor[HTML]{2CED14}\textbf{0.7545} & \cellcolor[HTML]{2CED14}\textbf{0.7224}                        \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}LDA $\,\to\,$ \\Naive Bayes\end{tabular}}     & \cellcolor[HTML]{FE0000}\textbf{0.5859}                        & \cellcolor[HTML]{2CED14}\textbf{0.8491} & \cellcolor[HTML]{FE0000}{\color[HTML]{333333} \textbf{0.6934}} \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}LDA $\,\to\,$\\AdaBoost \end{tabular}}    & \cellcolor[HTML]{2CED14}\textbf{0.7767}                        & \cellcolor[HTML]{2CED14}\textbf{0.74}   & \cellcolor[HTML]{2CED14}\textbf{0.7579}                        \\ \hline
\textbf{LDA $\,\to\,$ LASSO}                                                     & \cellcolor[HTML]{2CED14}\textbf{0.7433}                        & \cellcolor[HTML]{2CED14}\textbf{0.7055} & \cellcolor[HTML]{2CED14}\textbf{0.7239}                        \\ \hline
\textbf{LDA $\,\to\,$ k-NN}                                                      & \cellcolor[HTML]{FE0000}\textbf{0.6273}                        & \cellcolor[HTML]{2CED14}\textbf{0.82}   & \cellcolor[HTML]{2CED14}\textbf{0.7108}                        \\ \hline
\end{tabular}
\caption{Recall, precision and F1 scores from First Stage classifier combined with each possible second stage classifier.}
\end{table}

The First stage classifier, LDA is the same model combined with different second stage classifiers. One can see how LDA $\,\to\,$ SVM, LDA $\,\to\,$ Naive Bayes and LDA $\,\to\,$ k-Nearest Neighbors has a lower recall value, but a much larger precision value. On the other hand, LDA $\,\to\,$ AdaBoost and LDA $\,\to\,$ LASSO have a much more balanced recall-precision ratio, since both of their values are closer to each other, meaning that both AdaBoost and LASSO are good at avoiding both Type I and Type II errors. By observing the F1 scores, then LDA $\,\to\,$ AdaBoost outperforms every other combination of first stage-second stage classifier pairs, by having an F1-score of 0.7579. LDA $\,\to\,$ AdaBoost's largest F1-score is the main reason why the final 2 stage classification  system is composed of the interaction of these 2 models. Figure 5 shows the overall classification system's confusion matrix, after both models have been applied, and their predictions have been merged.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{images/Adaboost_mappedBack.png}
    \caption{Overall Classification system: LDA $\,\to\,$ Adaboost}
    \label{fig:word2vec}
\end{figure}

It is worth noting that the results from Figure 5 are only useful for calculating the final recall, precision and F1-scores for the overall two stage classifier system. The algorithm's final output is a 3 group classification of conversations based on each group's uncertainty level on maliciousness, which can be seen in Table 4. The 3 groups can be interpreted the following ways:
\begin{itemize}
        \item Group A: conversations most likely do not contain predatory behaviour
        \item Group B: conversations possibly could contain predatory behaviour
        \item Group C: conversations most likely contain predatory behaviour
\end{itemize}

\begin{table}[]
\centering
\label{3GroupClassification}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Group} & \textbf{\begin{tabular}[c]{@{}c@{}}Non-predatory\\ Conversations\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Predatory\\ Conversations\end{tabular}} \\ \hline
\textbf{A}     & \cellcolor[HTML]{2CED14}\textbf{98992}                                         & \cellcolor[HTML]{FE0000}\textbf{47}                                        \\ \hline
\textbf{B}     & \cellcolor[HTML]{2CED14}\textbf{341}                                           & \cellcolor[HTML]{FE0000}\textbf{96}                                        \\ \hline
\textbf{C}     & \cellcolor[HTML]{FE0000}\textbf{117}                                           & \cellcolor[HTML]{2CED14}\textbf{407}                                       \\ \hline
\end{tabular}
\caption{3 group classification of conversations, based on uncertainty levels of maliciousness}
\end{table}

Group A comes from the first stage classifier's upper half of the confusion matrix, where the Linear Discriminant model predicted the conversations to contain non-predatory behaviour. 

Group B comes from the second stage classifier's upper half of the confusion matrix, where the Linear Discriminant model predicted the conversations to contain predatory behavior, but the AdaBoost model filtered the conversations by predicting them not to contain predatory behaviour.

Group C comes from the second stage classifier's lower half of the confusion matrix, where both the Linear Discriminant and AdaBoost model predicted the conversations to contain predatory behaviour.

Classifying conversations in 3 different groups based on the uncertainty levels of their maliciousness is a good idea, since it makes the output of the classification system more flexible. In the same time, Groups A, B and C show how the decision whether or not a conversation contains predatory behaviour is not always binary, since there could be some grey areas in the interpretation of the content of the conversation.

\subsection{The Messy Nature of the Textual Data}
One of the key aspects of the algorithm designed is taking into consideration the nature of data being analyzed. It is worth emphasizing that online chat-room conversations are filled with misspelled words, slang, internet acronyms, inappropriate language, broken grammar, short, messy and unstructured textual data. The most challenging aspect of this project is finding a way to interpret and analyze textual data. These linguistic challenges have been addressed in 3 different ways. Firstly, the careful selection of the adequate text cleaning techniques is considered. Secondly, special emphasis is put on the insight that lies within the contextual details of a conversation. Thirdly, a domain specific feature extraction technique is being used to extract the essential details from each conversation. These three key components of the algorithm answer the first research question, which asked ``how to make modern computational language techniques and models adapt to the difficult to interpret nature of online conversations?".

\subsubsection{Advantages of Proper Text Cleaning}
%% reasoning behind each text cleaning techniques used
The text cleaning techniques used were white-space, HTML tag, hyperlink and numeric character removal, lowercase conversion, autocorrect. Surprisingly, extensive white spaces, HTML tags and hyperlinks show up in Inches and Crestani's sexual predatory conversations dataset quite often, and since Word2Vec is not built to extract meaning from random HTML tags and hyperlinks, their removal from the conversations was obvious. When using the Word2Vec model, it is considered standard practice to remove numerical values, since their interpretation depends on domain, country of origin and other contextual details that often impossible to retain from the conversation. The lowercase conversion of all textual data is done for the sole purpose of not making discrepancies between uppercase and lowercase spellings of the same word. Conversations containing less than 3 words have been discarded, since no meaningful interpretation of such short conversation could be made. Arguably the most important text cleaning tool used is \cite{mccallum_2016}'s library called autocorrect, which is a spelling corrector. This tool is necessary for the as accurate as possible interpretation of broken language and misspelled words or expressions.

\subsubsection{Insight in Contextual Details}
When it comes to the Sexual Predator Identification task, previous approaches included the identification of predators among all users in different conversations or identification of parts of conversations which are most distinctive of the predator behaviour. In order to come up with a unique approach, the algorithm is centered around detecting insight that lies within the contextual details of a conversation. More specifically, with the help of vector representation of words, and customized feature extraction, the vector representation of a whole conversation is obtained. These ``conversation feature vectors`` are composed of each conversation's contextual details detected by the Word2Vec model, then carefully selected and aggregated by a feature extraction process. The ``conversation feature vectors" obtained in such a manner are the essential input for classification models, which decide whether or not a conversation contains predatory behaviour. These concepts answer the research question formulated as ``how to extract semantic details from conversations, such that conversations containing malicious intent could be detected?". It is also worth noting that this approach considers the whole conversation as one large textual observation, without looking at discrepancies between each individual line in the conversation. To do so, the original labels from Inches and Crestani's dataset need to be parsed. The original labels are predatory line labels, which means that within each conversation, each line is labeled as predatory or non-predatory. The end goal of the label parsing process is to create conversation level labels, where each conversation contains a predatory/non-predatory label. This can be easily obtained by checking whether or not a predatory line is present within a conversation.

%% Feature extraction: word embedding aggregation using min-max value for each dimension technique + concatenation of min-max to obtain (2*numOfDim) feature vector features extracted from vector encoding of a conversation ... bag-of-words representation was already commonly used 

\subsubsection{Domain Specific Feature Extraction}
The feature extraction technique used in the algorithm is specific to only vector space representation of textual data. De Boom et al. stated that their technique was designed specifically for shorter text, that is messy, noisy and has a sparse vocabulary. They also noted that ``traditional textual representations, such as tf-idf \cite{sparck1972statistical}, have difficulty grasping the semantic meaning of such [messy and noisy] texts" \cite{de2016representation}. De Boom et al.'s work suggests that a simple feature extraction technique that seems to work reasonably well is to compute the vector embedding for each word in the conversation, then aggregate them using the coordinate-wise mean, min, max, or a combination of them. It is worth noting not all of De Boom et al.'s work has been used in this project, only their work on coordinate-wise word embedding aggregation functions. The benefits of word embedding aggregation functions are enormous, since coordinate-wise min and max functions applied to each word within a conversation tend to detect extreme values within the vector embedding, thus detecting unusual, or extreme meaning within the conversation. Furthermore, one could speculate that these extreme semantic values within the conversations could mean extreme behaviour within conversations, such as malicious, predatory intent. This observation can not be proven, but incorporating the detection of extreme coordinate-wise values within vector embeddings is a proper way to extract features from word embeddings.

\subsection{A Closer Look at the Vector Representation of Words Model Setup}
In terms of knowledge representation, the benefits of the Word2Vec model towards the algorithm proposed are essential. Word2Vec was chosen to be part of the algorithm as the one and only vector representation of words model, because it ``reconstructs the linguistic context of words and ...captures syntactic and semantic regularities in the language" \cite{mikolov2013linguistic}. Early in the research process it was not clear whether or not a pre-trained or a newly-trained Word2Vec model should be used. To address this concept, a couple of simple experiments have been conducted using a few famous pre-trained Word2Vec and Doc2Vec \cite{le2014distributed} models. Doc2Vec is a similar model to Word2Vec, and it was used to evaluate whether or not the vector embeddings created by pre-trained models are useful enough, when applied to Inches and Crestani's sexual predatory conversations dataset. The pre-trained models include Google's 300 dimensional Word2Vec model \cite{MikolovChenCorradoDean2013a} and a couple of different pre-trained Doc2Vec models coming from \cite{lau2016empirical}'s work, who experimented with document embedding generation. The experiments involved training a few classification models on the output of the above mentioned pre-trained models, and check if any correct conversation labels could be predicted from the vector embeddings. The pre-trained models could not provide any useful embeddings, since no classification model could make any accurate prediction based on the pre-trained vector embeddings. The simple and intuitive explanation for the above observation is that usually pre-trained models have been trained on specific data (e.g. all Wikipedia articles or news articles), but Inches and Crestani's sexual predatory conversations dataset does not necessarily match the same textual characteristics. In order to interpret the content of the conversation dataset, a Word2Vec model needs to be trained on the messy nature of the data described at the beginning of this section, therefore a self trained Word2Vec model was used during this research project, with the training data being Inches and Crestani's sexual predatory conversations dataset \cite{inches2012overview}.

Similar experiments have been conducted on the appropriate number of dimensions for the vectors in the Word2Vec model and the word embedding aggregation function used for feature extraction. The considered options were $dimensionSize =$ 200, 300, 400 or 500, while the aggregation functions for feature extraction suggested by De Boom et al. are coordinate-wise minimum, maximum, mean, or a combination of them, like concatenation of a coordinate-wise minimum and maximum vector. Coordinate-wise mean would get rid of extreme values within the vectors, which is undesirable for detection of malicious textual content, thus it was not considered. Numerous experiments have been conducted with various combinations of model dimension size and feature extraction function. To be more precise, 3 to 5 classification models have been trained for each of the following pairs of vector aggregation function - Word2Vec model size: Min-200, Max-200, MinMax-200, Min-300, Max-300, MinMax-300, Min-400, Max-400, MinMax-400, Min-500, Max-500, MinMax-500. As previously mentioned in the algorithm section, the best results on these experimental model pairs have been achieved by the 400 dimensional model, with the concatenated coordinate-wise minimum and maximum feature vectors, or just shortly the MinMax-400 model.

\subsection{A Closer Look at the Classification System}
\subsubsection{First Stage Classifier}
By studying the first stage classifier, one would probably like to understand why a Linear Discriminant model does so much better than most other predictive models. Without going too much into depth about what a Linear Discriminant model is and how it works, one just needs to understand how does the model make decide if an observation $x_i$ belongs to class $k=0 $ or $k=1$, where $x_i$ is an $n$ dimensional vector, and class $k$ is just a group within the data. Equation (1) \cite{tibshirani2013introduction} shows the calculation of the discriminant function, $\hat{\delta}_{k}$, which decides to what group does an observation belong to. There are multiple parameters for the discriminant function: $\hat{\mu }_{k}$ is the mean of the group $k$, while $\hat{\sigma}_{k}$ is the variance of the group $k$, and $\hat{\pi}_{k}$ is the prior class membership probability of a group $k$.
\begin{align}
	{{\hat{\delta }}}_{{k}}\left({x_i}\right)=x_i \cdot \frac {{{\hat{\mu }}}_{{k}}}{{{\hat{\sigma }}}^{{2}}}-\frac {{{\hat{\mu}}}_{{k}}^{{2}}}{2{\sigma }^{{2}}}+{log{\left({{{\hat{\pi }}}_{{k}}}\right)}} 
\end{align}

Firstly, LDA uses some estimation method to estimate the mean $\hat{\mu }_{k}$ and variance $\hat{\sigma}_{k}$ of a group $k$, then it requires to know or estimate the prior class membership probability, $\hat{\pi}_{k}$. After the parameters have been estimated, the LDA classifier plugs the estimates for $\hat{\mu }_{k}$, $\hat{\sigma}_{k}$ and $\hat{\pi}_{k}$ into equation (1), and assigns an observation $X$ = $x_i$ to the class for which $\hat{\delta}_{k}$ is the largest. One of the key parameters that can influence the discriminant function's decision is $\hat{\pi}_{k}$, the prior class membership probability of a group $k$. During training of the LDA model, the training data influences this parameter $\hat{\pi}_{k}$ by adjusting it to prior class weights of the training data, which is known, since the training data has labels. For the first stage classifier, the LDA model was trained on 100000 observations. Out of this training set 99450 observations belong to the non-predatory behaviour group ($k=0$), while 550 observations belong to the predatory behavior group ($k=1$), thus $\hat{\pi}_{0}$ = $0.99450$, while $\hat{\pi}_{1}$ = $0.00550$. These $\hat{\pi}_{k}$ values adjust the weighting on the probability that a new observation belongs to a class $k$, thus they had a massive influence on the performance and accuracy of the LDA model.

As LDA became First Stage Classifier, its performance was very good at identifying conversations that contain predatory behavior, but it was creating a concernedly large percentage of false positives, which in the end triggered the fitting of a second stage classifier. About half of the conversations flagged as containing predatory behaviour actually were non-predatory conversations being classified as predatory conversations. This means that too many ``innocent conversations were mislabeled, which affected the classification system's overall trustworthiness. The classification system needed a filtering model, which focused on lowering the overall amount of false positives, and it was called the second stage classifier.

\subsubsection{Second Stage Classifier}
In the second stage classification AdaBoost performs well, better than similar tree based methods like Random Forest or Bagging, since its algorithm is a similar, but improved version of Bagging. Boosting works in a sequential manner, as each tree within the AdaBoost model is fitted on random subsets of the original training set, without the use of Bootstrapping, then finally the iterative models are added up to create a strong classifier. Furthermore, since \cite{freund1996experiments} and \cite{hastie2009multi}'s AdaBoost algorithm includes iterative feedback to the sequence of models fitted using the weights of each observation being updated by the error rate, this provides an extra accuracy to the AdaBoost model fitted as the second stage classifier.

The LASSO model's performance is accurate as both a first and second stage classifier. It can be noted that the LASSO model's performance ranked in the top 5 most accurate models for both first and second stage classification process. Unfortunately, both times it was outperformed by other models, but nonetheless it is a great model, which is good minimizing both types of errors to some level of accuracy. With F1-scores of 0.6613 and 0.7574 for the first and respectively second stage classifier, one must wonder why such a model is worth taking into consideration for classification tasks. The explanation is simple: LASSO is supervised machine learning method, which is also known as a shrinkage and variable selection method for linear regression models. In this project LASSO is applied on the ``conversation feature vectors", which are 800 dimensional. One could only speculate which of those 800 dimensions are useful predictors for the Sexual Predatory Conversation Identification task, but the LASSO model can actually do so. By carefully choosing $\lambda$, the model's penalty term, the model applies constraints on the original coefficients, which end up shrinking the coefficients of useless predictors to zero. Penalizing the useless predictors results in selecting the most important variables associated with the response variable. The advantage of using LASSO for this classification task is great variable selection, which provides greater prediction accuracy and better model interpretability.

\subsection{Model Trade-off and Dimensionality Reduction}
A few observations worth mentioning are the trade-offs of using different models for second stage classification. A decision needs to be made on what to prioritize more: filtering out more ``non-predatory" conversations from type I errors or putting back more ``predatory" conversations into type II errors. For the sake of the argument, let's assume that the two stage classification system gets implemented by a company who process an online product which contains online chat-room. The moderators of the chat-room could choose to adjust the model used for the second stage classifier, based on their priority of minimizing either type I or type II errors. Using the SVM, Naive Bayes or k-NN classifier in the second stage would result in having less type II errors over more type I errors. On the other hand, using either the LASSO or AdaBoost model in the second stage balances out the first stage classifier's large number of type I errors, having a more less equal amount of type I and type II errors overall.

Lastly, there was an attempt on applying dimensionality reduction algorithms like Classical Multidimensional Scaling \cite{borg2005modern}, Principle Component Analysis and Factor Analysis \cite{jolliffe1986principal} on the ``conversation feature vectors" to reduce some of the 800 dimensions. The goal would have been to apply the classification system on the reduced feature vectors, but no real benefit was observed, since all classification models performed significantly worse after performing dimensionality reduction.  

\section{Future Works}
There are 3 main areas, where improvements could be made in the future: the representation of words in vector space, the feature extractor and the classification system. 

Firstly, Facebook's efficient learning of word representations and sentence classifications, FastText \cite{joulin2016bag} could be used to improve the quality of the word vector representation. Alternatively other vector space models like Doc2Vec \cite{le2014distributed}, Lda2Vec\cite{moody2016mixing}, ConceptNet Numberbatch \cite{speer2017conceptnet} or Sense2Vec \cite{trask2015sense2vec} could be experimented with. Secondly, the entire version of De Boom's algorithm \cite{de2016representation} could be used to create a better feature extractor by applying representation learning concepts combined with weighted word embedding aggregation. Thirdly, a deep learning approach could be considered for the classification system, by favouring prediction accuracy over model interpretability. 

\section{Conclusion}
This research project was proven to be the perfect combination of computational linguistics and statistical machine learning in order to find insight in the data. The main goal of the project was to design an approach that could detect and classify online conversations as either containing or not containing sexual predatory behaviour within the conversation. Throughout this project 100000 messy and unstructured online chat-room conversations were looked at, with the hopes of detecting a few needles in the haystack, 550 malicious conversations. With the help of deep learning language models, innovative feature extraction techniques, variety of statistical machine learning models, and exploration of contextual details a new, innovative and unique approach was born. The proposed algorithm uses models like Word2Vec, Linear Discriminant Analysis and AdaBoost to detect potential predatory behaviour with accuracy measured as a F1-score of 0.7579. The algorithm's two stage classification system creates a 3 group classification of conversations based on their uncertainty levels of maliciousness. One of the advantages of such classification system is that the second stage classifier could be easily switched to a different model to customize the system's priorities by minimizing either type I or type II errors. In the end, the algorithm aims to enhance children's safety in online environments by detecting malicious behaviour in online conversations. 

\section*{Acknowledgments}
I am grateful for my two supervisors, Abdallah and Jeff, who I would like to thank for their support and feedback throughout the entirety of the project. I would also like to thank a few undergraduate students, who reviewed my thesis multiple times and always provided great feedback.

% include your own bib file like this:
\bibliographystyle{apalike}
\bibliography{references} % references.bib is the name of the Bibliography in this case

\end{document}
